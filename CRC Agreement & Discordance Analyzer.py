import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
import itertools
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
import plotly.express as px
import pingouin as pg

# =========================
# Page Configuration
# =========================
st.set_page_config(page_title="CRC 6â€‘Rater Agreement Analyzer", layout="wide")
st.title("CRC 6â€‘Rater Agreement Analyzer")
st.caption("6ëª…ì˜ í‰ê°€ìê°€ 5ì  ì²™ë„ë¡œ í‰ê°€í•œ â‘  AI vs MDT, â‘¡ AI vs Guideline, â‘¢ MDT vs Guideline ì˜ ì¼ì¹˜ë„Â·ì‹ ë¢°ë„ì™€ ë¶ˆì¼ì¹˜ ìœ„í—˜ìš”ì¸(ë‹¤ë³€ëŸ‰ ë¡œì§€ìŠ¤í‹±)ì„ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤.")

# =========================
# Utilities & Statistical Functions
# =========================

@st.cache_data
def read_excel(file):
    """Uploaded Excel íŒŒì¼ì„ Pandas DataFrameìœ¼ë¡œ ì½ìŠµë‹ˆë‹¤."""
    try:
        return pd.read_excel(file)
    except Exception as e:
        st.error(f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

def safe_num(s):
    """ë¬¸ìì—´ì„ ìˆ«ìí˜•ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜í•©ë‹ˆë‹¤. ë³€í™˜ ì‹¤íŒ¨ ì‹œ NaT/NaNì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return pd.to_numeric(s, errors="coerce")

def make_distance_matrix(k: int, scheme: str = "quadratic") -> np.ndarray:
    """ê°€ì¤‘ ì¹´íŒŒ(Weighted Kappa) ê³„ì‚°ì„ ìœ„í•œ ê±°ë¦¬ í–‰ë ¬ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    idx = np.arange(k)
    D = np.zeros((k, k), dtype=float)
    for i in range(k):
        for j in range(k):
            d = abs(i - j) / (k - 1) if k > 1 else 0.0
            if scheme == "linear":
                D[i, j] = d
            elif scheme == "quadratic":
                D[i, j] = d ** 2
            else: # nominal / unweighted
                D[i, j] = 0.0 if i == j else 1.0
    return D

def weighted_kappa_custom(a: pd.Series, b: pd.Series, labels, D: np.ndarray) -> float:
    """ë‘ í‰ê°€ì ê°„ì˜ ê°€ì¤‘ ì¹´íŒŒ(Weighted Kappa)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    df = pd.DataFrame({"a": a, "b": b}).dropna()
    if df.empty:
        return np.nan
    lab_to_i = {lab: i for i, lab in enumerate(labels)}
    ai = df["a"].map(lab_to_i)
    bi = df["b"].map(lab_to_i)
    k = len(labels)
    cm = np.zeros((k, k), dtype=float)
    for i_, j_ in zip(ai, bi):
        if pd.isna(i_) or pd.isna(j_):
            continue
        cm[int(i_), int(j_)] += 1
    n = cm.sum()
    if n == 0: return np.nan
    r = cm.sum(axis=1)
    c = cm.sum(axis=0)
    Do = (D * cm).sum()
    E = np.outer(r, c) / n
    De = (D * E).sum()
    if De == 0: return np.nan
    return float(1.0 - Do / De)

def bootstrap_ci_stat(stat_fun, n_items: int, B: int = 2000, seed: int = 42):
    """í†µê³„ëŸ‰ì˜ ë¶€íŠ¸ìŠ¤íŠ¸ë© ì‹ ë¢°êµ¬ê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    rng = np.random.default_rng(seed)
    vals = []
    for _ in range(B):
        idx = rng.integers(0, n_items, n_items)
        vals.append(stat_fun(idx))
    vals = np.array(vals, dtype=float)
    lo, hi = np.nanpercentile(vals, [2.5, 97.5])
    p_boot = 2 * min((vals <= 0).mean(), (vals >= 0).mean())
    return float(lo), float(hi), float(p_boot), vals

def fleiss_kappa(ratings_df: pd.DataFrame, B: int = 2000, seed: int = 42):
    """ë‹¤ìˆ˜ í‰ê°€ì ê°„ì˜ Fleiss' Kappaë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (ë¹„ê°€ì¤‘ì¹˜, ê²°ì¸¡ì¹˜ í—ˆìš©)."""
    X = ratings_df.copy()
    if X.empty:
        return np.nan, np.nan, np.nan, np.array([])
    
    cats = sorted([c for c in pd.unique(X.values.ravel()) if pd.notna(c)])
    if not cats: return np.nan, np.nan, np.nan, np.array([])
    
    m = len(cats)
    cat_to_i = {c: i for i, c in enumerate(cats)}
    n_items = X.shape[0]

    def calculate_kappa(df_sub):
        n_items_sub = df_sub.shape[0]
        if n_items_sub == 0: return np.nan

        N = np.zeros((n_items_sub, m), dtype=float)
        for u in range(n_items_sub):
            vc = pd.Series(df_sub.iloc[u, :]).dropna().value_counts()
            for c, cnt in vc.items():
                if c in cat_to_i:
                    N[u, cat_to_i[c]] = cnt
        
        n_i = N.sum(axis=1)
        valid_items_mask = n_i >= 2
        if not np.any(valid_items_mask): return np.nan
        
        N = N[valid_items_mask, :]
        n_i = n_i[valid_items_mask]
        
        Pu = (np.sum(N * (N - 1), axis=1)) / (n_i * (n_i - 1))
        P_bar = np.nanmean(Pu)
        
        total_ratings = np.sum(n_i)
        if total_ratings == 0: return np.nan
        
        pj = np.sum(N, axis=0) / total_ratings
        Pe = np.sum(pj ** 2)
        
        if (1 - Pe) == 0: return np.nan
        kappa = (P_bar - Pe) / (1 - Pe)
        return kappa

    kappa_0 = calculate_kappa(X)
    rng = np.random.default_rng(seed)
    boots = [calculate_kappa(X.iloc[rng.integers(0, n_items, n_items)]) for _ in range(B)]
    boots = np.array(boots, dtype=float)
    lo, hi = np.nanpercentile(boots, [2.5, 97.5])
    return float(kappa_0), float(lo), float(hi), boots

def krippendorff_alpha(ratings_df: pd.DataFrame, B: int = 2000, seed: int = 42):
    """ë‹¤ìˆ˜ í‰ê°€ì ê°„ì˜ Krippendorff's Alphaë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (ì„œì—´ì²™ë„)."""
    X = ratings_df.copy()
    cats = sorted([c for c in pd.unique(X.values.ravel()) if pd.notna(c)])
    if not cats: return np.nan, np.nan, np.nan, np.array([])
    
    cat_to_i = {c: i for i, c in enumerate(cats)}
    m = len(cats)

    def calculate_alpha(df):
        O = np.zeros((m, m), dtype=float)
        for _, row in df.iterrows():
            vals = [v for v in row.values if pd.notna(v)]
            if len(vals) < 2: continue
            vc = pd.Series(vals).value_counts()
            for i_c, ci in vc.items():
                ii = cat_to_i[i_c]
                O[ii, ii] += ci * (ci - 1)
                for j_c, cj in vc.items():
                    if j_c != i_c:
                        jj = cat_to_i[j_c]
                        O[ii, jj] += ci * cj
        
        if O.sum() == 0: return np.nan
        D = np.zeros((m, m), dtype=float)
        for i in range(m):
            for j in range(m):
                d = abs(i - j) / (m - 1) if m > 1 else 0.0
                D[i, j] = d ** 2
        
        Do = (O * D).sum() / O.sum()
        n_i = O.sum(axis=1)
        E = np.outer(n_i, n_i)
        for i in range(m): E[i, i] = n_i[i] * (n_i[i] - 1)
        if E.sum() == 0: return np.nan
        De = (E * D).sum() / E.sum()
        if De == 0: return np.nan
        return 1.0 - Do / De

    alpha = calculate_alpha(X)
    rng = np.random.default_rng(seed)
    n_items = len(X)
    boots = [calculate_alpha(X.iloc[rng.integers(0, n_items, n_items)]) for _ in range(B)]
    boots = np.array(boots, dtype=float)
    lo, hi = np.nanpercentile(boots, [2.5, 97.5])
    return float(alpha), float(lo), float(hi), boots

def calculate_icc(ratings_df: pd.DataFrame):
    """Intraclass Correlation Coefficient (ICC)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    df_long = ratings_df.reset_index().melt(
        id_vars='index', var_name='rater', value_name='rating'
    ).rename(columns={'index': 'case'}).dropna()
    
    if df_long.empty or df_long['case'].nunique() < 2 or df_long['rater'].nunique() < 2:
        return np.nan, np.nan, np.nan
    try:
        icc = pg.intraclass_corr(data=df_long, targets='case', raters='rater', ratings='rating', nan_policy='omit')
        icc.set_index('Type', inplace=True)
        icc_res = icc.loc['ICC2k'] # Two-way random, mean rating, absolute agreement
        val, ci = icc_res['ICC'], icc_res['CI95%']
        return val, ci[0], ci[1]
    except Exception:
        return np.nan, np.nan, np.nan

def pairwise_kappa_table(raters_df: pd.DataFrame, labels, D: np.ndarray, B: int = 2000, seed: int = 42):
    """ëª¨ë“  í‰ê°€ì ìŒì— ëŒ€í•œ ê°€ì¤‘ ì¹´íŒŒ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    rows = []
    n = len(raters_df)
    if n == 0: return pd.DataFrame()
    
    for a, b in itertools.combinations(raters_df.columns, 2):
        def stat_fun(idx):
            return weighted_kappa_custom(raters_df[a].iloc[idx], raters_df[b].iloc[idx], labels, D)
        k0 = stat_fun(np.arange(n))
        lo, hi, p_boot, _ = bootstrap_ci_stat(stat_fun, n, B=B, seed=seed)
        pea = float((raters_df[a] == raters_df[b]).mean()) * 100.0
        rows.append({
            "Rater A": a, "Rater B": b,
            "Exact Agreement (%)": f"{pea:.2f}",
            "Weighted Kappa": f"{k0:.4f}",
            "95% CI Lower": f"{lo:.4f}",
            "95% CI Upper": f"{hi:.4f}",
            "P-value (Boot)": f"{p_boot:.4f}"
        })
    return pd.DataFrame(rows)

def lights_kappa(raters_df: pd.DataFrame, labels, D: np.ndarray, B: int = 2000, seed: int = 42):
    """Light's Kappa (ëª¨ë“  ìŒë³„ ì¹´íŒŒì˜ í‰ê· )ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    pairs = list(itertools.combinations(raters_df.columns, 2))
    n = len(raters_df)
    if n == 0: return np.nan, np.nan, np.nan, np.array([])
    def lk_from_idx(idx):
        vals = [weighted_kappa_custom(raters_df[a].iloc[idx], raters_df[b].iloc[idx], labels, D) for a, b in pairs]
        return float(np.nanmean(vals))
    k0 = lk_from_idx(np.arange(n))
    lo, hi, _, boots = bootstrap_ci_stat(lk_from_idx, n, B=B, seed=seed)
    return float(k0), float(lo), float(hi), boots

def fit_logit(df: pd.DataFrame, y_col: str, x_cols, robust=True):
    """ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ ì í•©í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    X = df[x_cols].copy()
    cat_cols = [c for c in x_cols if (not pd.api.types.is_numeric_dtype(X[c])) or X[c].nunique() <= 6]
    X = pd.get_dummies(X, columns=cat_cols, drop_first=True, dtype=float)
    X = X.replace([np.inf, -np.inf], np.nan).dropna()
    y = df.loc[X.index, y_col].astype(int)
    
    if len(X) < len(x_cols) + 1:
        raise ValueError("ìƒ˜í”Œ ìˆ˜ê°€ ë³€ìˆ˜ ìˆ˜ë³´ë‹¤ ì ì–´ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    if y.nunique() < 2:
        raise ValueError("ì¢…ì†ë³€ìˆ˜(ë¶ˆì¼ì¹˜ ì—¬ë¶€)ì— ë‘ ê°€ì§€ ì´ìƒì˜ ë²”ì£¼ê°€ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.")

    X = sm.add_constant(X, has_constant="add")
    model = sm.Logit(y, X)
    res = model.fit(disp=False, maxiter=200)
    if robust: res = res.get_robustcov_results(cov_type="HC3")
    
    params, conf = res.params, res.conf_int()
    out = pd.DataFrame({
        "Variable": params.index, "OR": np.exp(params),
        "CI Lower": np.exp(conf.iloc[:, 0]), "CI Upper": np.exp(conf.iloc[:, 1]),
        "P-value": res.pvalues
    }).round(4)
    out = out[out["Variable"] != "const"].reset_index(drop=True)
    
    vif_rows, Xv = [], X.drop(columns=["const"], errors="ignore")
    if Xv.shape[1] >= 2:
        for i in range(Xv.shape[1]):
            vif_rows.append({"Variable": Xv.columns[i], "VIF": variance_inflation_factor(Xv.values, i)})
    return res, out, pd.DataFrame(vif_rows)

def infer_labels(raters_df: pd.DataFrame):
    """í‰ê°€ ë°ì´í„°ì—ì„œ ê³ ìœ í•œ ë¼ë²¨(ì²™ë„)ì„ ì¶”ë¡ í•©ë‹ˆë‹¤."""
    vals = pd.unique(raters_df.values.ravel())
    vals = sorted([v for v in vals if pd.notna(v)])
    return vals if vals else [1, 2, 3, 4, 5]

# =========================
# Sidebar â€“ Upload & Settings
# =========================
with st.sidebar:
    st.header("1) íŒŒì¼ ì—…ë¡œë“œ & ì„¤ì •")
    up = st.file_uploader("Excel (.xlsx)", type=["xlsx"], help="Wide í˜•ì‹ì˜ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    if st.button("ìƒ˜í”Œ í…œí”Œë¦¿(.xlsx) ë‹¤ìš´ë¡œë“œ"):
        n=300; np.random.seed(0)
        def r5(n): return np.random.choice([1,2,3,4,5], n, p=[0.1,0.2,0.4,0.2,0.1])
        df_tmp = pd.DataFrame({ "case_id": [f"C{str(i+1).zfill(3)}" for i in range(n)], "A_M_S1": r5(n), "A_M_S2": r5(n), "A_M_S3": r5(n), "A_M_S4": r5(n), "A_M_S5": r5(n), "A_M_S6": r5(n), "A_G_S1": r5(n), "A_G_S2": r5(n), "A_G_S3": r5(n), "A_G_S4": r5(n), "A_G_S5": r5(n), "A_G_S6": r5(n), "M_G_S1": r5(n), "M_G_S2": r5(n), "M_G_S3": r5(n), "M_G_S4": r5(n), "M_G_S5": r5(n), "M_G_S6": r5(n), "age": np.random.normal(65, 10, n).round().astype(int), "sex": np.random.choice(["M","F"], n), "ASA": np.random.choice([1,2,3,4],n,p=[0.1,0.4,0.4,0.1]),"ECOG":np.random.choice([0,1,2,3],n,p=[0.3,0.4,0.2,0.1]), "T": np.random.choice(["T1","T2","T3","T4"],n,p=[0.1,0.2,0.5,0.2]),"N":np.random.choice(["N0","N1","N2"],n,p=[0.5,0.3,0.2]), "stage":np.random.choice(["I","II","III","IV"],n,p=[0.1,0.4,0.4,0.1]),"PNI":np.random.choice([0,1],n,p=[0.7,0.3]), "EMVI":np.random.choice([0,1],n,p=[0.7,0.3]),"obstruction":np.random.choice([0,1],n,p=[0.7,0.3])})
        bio = BytesIO()
        with pd.ExcelWriter(bio, engine="openpyxl") as w: df_tmp.to_excel(w, index=False, sheet_name="data")
        bio.seek(0)
        st.download_button("sample_template.xlsx ë‹¤ìš´ë¡œë“œ", data=bio, file_name="sample_template.xlsx", key="download_template")

    st.divider(); st.header("2) ë¶„ì„ ì„¤ì •")
    B = st.number_input(
        "Bootstrap ë°˜ë³µ íšŸìˆ˜", 
        min_value=100, 
        value=2000, 
        step=100, 
        help="ì‹ ë¢°êµ¬ê°„ ì¶”ì • ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜. ë†’ì„ìˆ˜ë¡ ì•ˆì •ì ì´ì§€ë§Œ ê³„ì‚° ì‹œê°„ì´ ê¸¸ì–´ì§‘ë‹ˆë‹¤."
    )
    seed = st.number_input("Random Seed", value=42, min_value=0, step=1, help="ë¶„ì„ ì¬í˜„ì„±ì„ ìœ„í•œ ë‚œìˆ˜ ì‹œë“œ. ê°™ì€ ì‹œë“œë¥¼ ì‚¬ìš©í•˜ë©´ í•­ìƒ ë™ì¼í•œ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤.")
    scheme = st.selectbox("ê°€ì¤‘ ë°©ì‹ (Kappa)", ["quadratic","linear","unweighted"], 0, help="ê°€ì¤‘ ì¹´íŒŒ ê³„ì‚° ì‹œ ë¶ˆì¼ì¹˜ì— ëŒ€í•œ í˜ë„í‹° ë°©ì‹ì…ë‹ˆë‹¤. Quadraticì€ ì°¨ì´ê°€ í´ìˆ˜ë¡ í˜ë„í‹°ë¥¼ ë” í¬ê²Œ ë¶€ì—¬í•©ë‹ˆë‹¤.")
    st.divider()
    if st.button("ëª¨ë“  ì„¤ì • ë° ë°ì´í„° ì´ˆê¸°í™”", type="secondary"): st.session_state.clear(); st.rerun()

if up is None:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ìƒ˜í”Œ í…œí”Œë¦¿ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.")
    st.stop()

# =========================
# Main Panel Logic
# =========================
df = read_excel(up)
if df is None: st.stop()

if 'df_shape' not in st.session_state or st.session_state.df_shape != df.shape:
    st.session_state.clear()
    st.session_state.df_shape = df.shape

st.success(f"íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {df.shape[0]} í–‰ Ã— {df.shape[1]} ì—´")
df.reset_index(inplace=True) # Use index for unique case identification

with st.expander("STEP 1: ë¶„ì„í•  ì—´ ì„ íƒ (ê° ë¹„êµìŒë³„ í‰ê°€ì 6ëª…)", expanded=True):
    cols = df.columns.tolist()
    st.session_state.case_id_col = st.selectbox("í™˜ì ID ì—´", cols, index=cols.index("case_id") if "case_id" in cols else 0, key="case_id_select")
    st.markdown("---")
    c1, c2, c3 = st.columns(3)
    with c1: st.session_state.am_cols = st.multiselect("**AI vs MDT**", cols, default=[c for c in cols if c.startswith("A_M_S")][:6], key="am_cols_select")
    with c2: st.session_state.ag_cols = st.multiselect("**AI vs Guideline**", cols, default=[c for c in cols if c.startswith("A_G_S")][:6], key="ag_cols_select")
    with c3: st.session_state.mg_cols = st.multiselect("**MDT vs Guideline**", cols, default=[c for c in cols if c.startswith("M_G_S")][:6], key="mg_cols_select")

for c in st.session_state.am_cols + st.session_state.ag_cols + st.session_state.mg_cols:
    if c in df.columns: df[c] = safe_num(df[c])

pair_tabs = st.tabs(["AI vs MDT", "AI vs Guideline", "MDT vs Guideline", "ë¶ˆì¼ì¹˜ ìœ„í—˜ìš”ì¸ ë¶„ì„"])

def render_pair_block(name: str, cols: list[str]):
    st.subheader(f"ğŸ“Š {name} â€” 6ì¸ í‰ê°€ ì¼ì¹˜ë„/ì‹ ë¢°ë„ ë¶„ì„")
    if len(cols) != 6: st.warning("ğŸ‘ˆ ìœ„ì—ì„œ í‰ê°€ì 6ëª…ì˜ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”."); return {}, {}
    
    R = df[cols].copy()
    if R.dropna(how='all').empty: st.error("ì„ íƒí•œ ì—´ì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return {}, {}
    
    labels, D = infer_labels(R), make_distance_matrix(len(infer_labels(R)), scheme)
    try:
        pair_tab = pairwise_kappa_table(R, labels, D, B=B, seed=seed)
        lk, llo, lhi, _ = lights_kappa(R, labels, D, B=B, seed=seed)
        fk, fk_lo, fk_hi, _ = fleiss_kappa(R, B=B, seed=seed)
        ka, ka_lo, ka_hi, _ = krippendorff_alpha(R, B=B, seed=seed)
        icc, icc_lo, icc_hi = calculate_icc(R)
    except Exception as e: st.error(f"í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); return {}, {}

    c1, c2 = st.columns(2)
    with c1:
        st.info("ìŒë³„ ê°€ì¤‘ Kappa (Weighted Kappa)", icon="â„¹ï¸")
        st.caption("ëª¨ë“  í‰ê°€ì ìŒ(15ê°œ)ì— ëŒ€í•´ ê°€ì¤‘ ì¹´íŒŒë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")
        st.dataframe(pair_tab, use_container_width=True)
        st.info("ì¢…í•© ì‹ ë¢°ë„ ì§€í‘œ", icon="â„¹ï¸")
        st.caption("ICC: í‰ê°€ì ê°„ ì‹ ë¢°ë„, í‰ê· ì ìˆ˜ì˜ ì‹ ë¢°ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\nLight's Kappa: ëª¨ë“  ìŒë³„ ê°€ì¤‘ ì¹´íŒŒì˜ í‰ê· ì…ë‹ˆë‹¤.\nFleiss' Kappa: ë‹¤ìˆ˜ í‰ê°€ì ê°„ ì¼ì¹˜ë„ (ë¹„ê°€ì¤‘ì¹˜).\nKrippendorff's Alpha: ìœ ì—°ì„±ì´ ë†’ì€ ì‹ ë¢°ë„ ì§€í‘œ (ì„œì—´ì²™ë„).")
        summary_df = pd.DataFrame([
            {"Metric": "ICC (2,k) - Absolute Agreement", "Value": f"{icc:.4f}", "95% CI": f"({icc_lo:.4f} - {icc_hi:.4f})"},
            {"Metric": "Light's Kappa (weighted)", "Value": f"{lk:.4f}", "95% CI": f"({llo:.4f} - {lhi:.4f})"},
            {"Metric": "Fleiss' Kappa (unweighted)", "Value": f"{fk:.4f}", "95% CI": f"({fk_lo:.4f} - {fk_hi:.4f})"},
            {"Metric": "Krippendorff's Alpha (ordinal)", "Value": f"{ka:.4f}", "95% CI": f"({ka_lo:.4f} - {ka_hi:.4f})"},
        ]).set_index("Metric")
        st.dataframe(summary_df, use_container_width=True)

    with c2:
        st.info("í•©ì˜ ì ìˆ˜(Consensus Score) ë¶„í¬", icon="â„¹ï¸")
        st.caption("ê° ì¼€ì´ìŠ¤ë³„ 6ì¸ í‰ê°€ì˜ ì¤‘ì•™ê°’(median)ì„ í•©ì˜ ì ìˆ˜ë¡œ ì •ì˜í•˜ê³ , ê·¸ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        consensus = R.median(axis=1, skipna=True)
        fig = px.histogram(consensus.dropna(), nbins=len(labels)*2, title=f"<b>{name}: í•©ì˜ ì ìˆ˜ ë¶„í¬</b>")
        fig.update_layout(showlegend=False, yaxis_title="ì¼€ì´ìŠ¤ ìˆ˜", xaxis_title="í•©ì˜ ì ìˆ˜ (ì¤‘ì•™ê°’)")
        st.plotly_chart(fig, use_container_width=True)
        
        st.info("ì „ì²´ í‰ì  ë¶„í¬", icon="â„¹ï¸")
        st.caption("ëª¨ë“  í‰ê°€ìì™€ ì¼€ì´ìŠ¤ì— ê±¸ì³ ê° ì ìˆ˜ê°€ ëª‡ ë²ˆì”© ë¶€ì—¬ë˜ì—ˆëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        ratings_long = R.melt(var_name='rater', value_name='rating').dropna()
        fig2 = px.histogram(ratings_long, x='rating', title=f"<b>{name}: ì „ì²´ í‰ì  ë¶„í¬</b>", category_orders={"rating": labels})
        fig2.update_layout(yaxis_title="ë¹ˆë„ ìˆ˜", xaxis_title="í‰ì ")
        st.plotly_chart(fig2, use_container_width=True)


    with st.expander("ì¼€ì´ìŠ¤ë³„ ë¶ˆì¼ì¹˜ ë¶„ì„ ë³´ê¸° (Top 10)"):
        st.caption("ê° ì¼€ì´ìŠ¤ì— ëŒ€í•œ 6ëª… í‰ê°€ì˜ í‘œì¤€í¸ì°¨(StDev)ë¥¼ ê³„ì‚°í•˜ì—¬ ë¶ˆì¼ì¹˜ê°€ ê°€ì¥ í° ìƒìœ„ 10ê°œ ì¼€ì´ìŠ¤ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        disagreement = R.std(axis=1, skipna=True).sort_values(ascending=False)
        top_10_df = df.loc[disagreement.head(10).index, [st.session_state.case_id_col] + cols]
        top_10_df['Disagreement (StDev)'] = disagreement.head(10)
        st.dataframe(top_10_df.style.format({'Disagreement (StDev)': "{:.4f}"}), use_container_width=True)

    out_tables = { f"{name}_pairwise_kappa": pair_tab, f"{name}_summary_reliability": summary_df.reset_index(), f"{name}_top_disagreement": top_10_df }
    return out_tables, {"consensus": consensus}

with pair_tabs[0]: st.session_state.tables_am, st.session_state.meta_am = render_pair_block("AI_vs_MDT", st.session_state.am_cols)
with pair_tabs[1]: st.session_state.tables_ag, st.session_state.meta_ag = render_pair_block("AI_vs_Guideline", st.session_state.ag_cols)
with pair_tabs[2]: st.session_state.tables_mg, st.session_state.meta_mg = render_pair_block("MDT_vs_Guideline", st.session_state.mg_cols)

with pair_tabs[3]:
    st.subheader("âš¡ï¸ ë¶ˆì¼ì¹˜ ìœ„í—˜ìš”ì¸ ë¶„ì„ (ë‹¤ë³€ëŸ‰ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„)")
    meta_map = {"AI_vs_MDT": st.session_state.get('meta_am',{}), "AI_vs_Guideline": st.session_state.get('meta_ag',{}), "MDT_vs_Guideline": st.session_state.get('meta_mg',{})}
    c1,c2 = st.columns(2)
    with c1: pair = st.selectbox("ë¶„ì„í•  ë¹„êµìŒ", list(meta_map.keys()), key="logit_pair", help="ì–´ë–¤ ë¹„êµìŒì˜ ë¶ˆì¼ì¹˜ ìœ„í—˜ìš”ì¸ì„ ë¶„ì„í• ì§€ ì„ íƒí•©ë‹ˆë‹¤.")
    with c2: thr = st.number_input("ë¶ˆì¼ì¹˜(Discordance) ì •ì˜ ì„ê³„ê°’", 1, 5, 2, 1, help="í•©ì˜ ì ìˆ˜(ì¤‘ì•™ê°’)ê°€ ì´ ê°’ 'ì´í•˜'ì¼ ê²½ìš°ë¥¼ ë¶ˆì¼ì¹˜(1)ë¡œ ì •ì˜í•©ë‹ˆë‹¤.")

    if 'consensus' not in meta_map[pair]: st.warning(f"ë¨¼ì € '{pair}' íƒ­ì—ì„œ ì¼ì¹˜ë„ ë¶„ì„ì„ ì‹¤í–‰í•˜ì—¬ í•©ì˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤."); st.stop()
    
    df["_discordant"] = (meta_map[pair]['consensus'] <= thr).astype(int)
    st.info(f"'{pair}' ë¹„êµìŒì—ì„œ í•©ì˜ ì ìˆ˜ê°€ **{thr} ì´í•˜**ì¸ ê²½ìš°ë¥¼ 'ë¶ˆì¼ì¹˜'ë¡œ ì •ì˜í–ˆìŠµë‹ˆë‹¤. (ì´ {df['_discordant'].sum()} / {len(df['_discordant'].dropna())} ì¼€ì´ìŠ¤)")

    excluded = {st.session_state.case_id_col, "_discordant", "index"} | set(st.session_state.am_cols) | set(st.session_state.ag_cols) | set(st.session_state.mg_cols)
    candidates = [c for c in df.columns if c not in excluded]
    default_covars = [c for c in candidates if c in ["age", "sex", "ASA", "ECOG", "stage", "T", "N", "PNI", "EMVI", "obstruction"]]
    covars = st.multiselect("ë¶„ì„ì— í¬í•¨í•  ê³µë³€ëŸ‰(ë…ë¦½ë³€ìˆ˜)", candidates, default=default_covars, key="logit_covars", help="ë¶ˆì¼ì¹˜ì— ì˜í–¥ì„ ì¤„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ë³€ìˆ˜ë“¤ì„ ì„ íƒí•©ë‹ˆë‹¤.")
    robust = st.checkbox("Robust Standard Errors (HC3) ì‚¬ìš©", True, help="ì´ìƒì¹˜(outlier) ë“±ì— ëœ ë¯¼ê°í•œ ê°•ê±´í•œ í‘œì¤€ì˜¤ì°¨ë¥¼ ì‚¬ìš©í•˜ì—¬ p-valueë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")

    if st.button("ìœ„í—˜ìš”ì¸ ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True) and covars:
        try:
            res, or_tab, vif_df = fit_logit(df.dropna(subset=covars+['_discordant']), "_discordant", covars, robust=robust)
            st.session_state.or_tab, st.session_state.vif_df, st.session_state.logit_summary = or_tab, vif_df, res.summary2().as_text()
        except Exception as e: st.error(f"ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ ì˜¤ë¥˜: {e}"); st.session_state.or_tab = None

    if 'or_tab' in st.session_state and st.session_state.or_tab is not None:
        st.markdown("---"); st.subheader("ë¶„ì„ ê²°ê³¼")
        c1, c2 = st.columns([0.6, 0.4])
        with c1:
            st.info("Odds Ratio (OR) Plot", icon="ğŸ“ˆ")
            st.caption("ORì´ 1ë³´ë‹¤ í¬ë©´ ë¶ˆì¼ì¹˜ ìœ„í—˜ì„ ë†’ì´ëŠ” ìš”ì¸, 1ë³´ë‹¤ ì‘ìœ¼ë©´ ë‚®ì¶”ëŠ” ìš”ì¸ì…ë‹ˆë‹¤.")
            fig = px.scatter(st.session_state.or_tab, x="OR", y="Variable", error_x="CI Upper", error_x_minus="CI Lower", log_x=True, labels={"Variable":""}, title="<b>ë¶ˆì¼ì¹˜ ìœ„í—˜ìš”ì¸ Odds Ratios</b>")
            fig.add_vline(x=1, line_dash="dash", line_color="grey"); fig.update_yaxes(autorange="reversed")
            st.plotly_chart(fig, use_container_width=True)
        with c2:
            st.info("Odds Ratio (OR) Table", icon="ğŸ“‹"); st.dataframe(st.session_state.or_tab.style.format(precision=4), use_container_width=True)
            st.info("ë‹¤ì¤‘ê³µì„ ì„± (VIF)", icon="âš ï¸"); st.caption("VIFê°€ ë³´í†µ 10ì„ ì´ˆê³¼í•˜ë©´ ë‹¤ì¤‘ê³µì„ ì„±ì„ ì˜ì‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.dataframe(st.session_state.vif_df.sort_values("VIF", ascending=False).style.format({"VIF": "{:.2f}"}), use_container_width=True)
        with st.expander("ì „ì²´ ëª¨ë¸ ìš”ì•½ ë³´ê¸° (Statsmodels)"): st.text(st.session_state.logit_summary)

# =========================
# Export Results
# =========================
st.divider()
st.subheader("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)")
def build_results_workbook():
    tables = {}
    for key in ['tables_am', 'tables_ag', 'tables_mg']:
        if key in st.session_state: tables.update(st.session_state[key] or {})
    if 'or_tab' in st.session_state and st.session_state.or_tab is not None:
        tables[f"RiskFactors_{st.session_state.logit_pair}"] = st.session_state.or_tab
        tables[f"VIF_{st.session_state.logit_pair}"] = st.session_state.vif_df
    if not tables: st.warning("ë‹¤ìš´ë¡œë“œí•  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."); return None

    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        for name, table_df in tables.items():
            if isinstance(table_df, pd.DataFrame) and not table_df.empty:
                table_df.to_excel(writer, sheet_name=name[:31], index=False)
    bio.seek(0)
    return bio

try:
    xls_data = build_results_workbook()
    if xls_data:
        st.download_button("í†µí•© ë¶„ì„ ê²°ê³¼ (results.xlsx) ë‹¤ìš´ë¡œë“œ", xls_data, "CRC_Agreement_Analysis_Results.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
except Exception as e: st.error(f"ê²°ê³¼ íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

st.caption("Â© 2025 â€” CRC 6â€‘Rater Agreement Analyzer (Enhanced by Gemini)")

